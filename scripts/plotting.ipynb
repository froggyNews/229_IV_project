{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e6a06c",
   "metadata": {},
   "source": [
    "### Slides 10–13: Timeframe-Aware Plots\n",
    "- Heatmaps: IV level and IV return correlations.\n",
    "- Optional: Rolling correlation of IV returns (target vs peers).\n",
    "- Pooled XGBoost importances for levels and returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from baseline_correlation import compute_baseline_correlations\n",
    "from data_loader_coordinator import load_cores_with_auto_fetch\n",
    "from feature_engineering import build_iv_panel, DEFAULT_DB_PATH, build_pooled_iv_return_dataset_time_safe\n",
    "\n",
    "# User-configurable parameters\n",
    "tickers = [\"QBTS\", \"IONQ\", \"RGTI\", \"QUBT\"]  # edit as needed\n",
    "target_ticker = \"QBTS\"                                # for rolling correlation\n",
    "start = os.getenv(\"SLIDE_START\", \"2025-01-02\")\n",
    "end = os.getenv(\"SLIDE_END\", \"2025-08-27\")\n",
    "timeframe = os.getenv(\"SLIDE_TIMEFRAME\", \"1h\").lower()  # '1h' or '1m'\n",
    "\n",
    "# Resolve DB path: env IV_DB_PATH > DEFAULT_DB_PATH; override for timeframe if needed\n",
    "env_db = os.getenv(\"IV_DB_PATH\")\n",
    "db_path = Path(env_db) if env_db else DEFAULT_DB_PATH\n",
    "if timeframe == '1m' and str(db_path).endswith('iv_data_1h.db'):\n",
    "    db_path = Path('data/iv_data_1m.db')\n",
    "\n",
    "# Timeframe-aware defaults\n",
    "forward_steps = 60 if timeframe == '1m' else 15\n",
    "tolerance = '30s' if timeframe == '1m' else '15s'\n",
    "roll_window = 23400 if timeframe == '1m' else 390\n",
    "\n",
    "plots_dir = Path('plots')\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Tickers: {tickers}')\n",
    "print(f'Date range: {start} to {end}')\n",
    "print(f'Database: {db_path} | timeframe={timeframe} | tol={tolerance} | fwd={forward_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d79ae1b",
   "metadata": {},
   "source": [
    "#### Slide 10 — Correlation Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fe4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = compute_baseline_correlations(tickers=tickers, start=start, end=end, db_path=db_path)\n",
    "clip_corr = corrs.get('clip', pd.DataFrame())\n",
    "ivret_corr = corrs.get('iv_returns', pd.DataFrame())\n",
    "\n",
    "def _plot_heatmap(df, title, fname):\n",
    "    if df is None or df.empty:\n",
    "        print(f'[WARN] {title}: not enough data to plot')\n",
    "        return\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.2f')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    out = plots_dir / fname\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.show()\n",
    "    print(f'[SAVED] {out}')\n",
    "\n",
    "_plot_heatmap(clip_corr, 'IV Level Correlations', 'slide10_iv_level_corr_heatmap.png')\n",
    "_plot_heatmap(ivret_corr, 'IV Return Correlations', 'slide10_iv_return_corr_heatmap.png')\n",
    "\n",
    "clip_corr\n",
    "ivret_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dea9a",
   "metadata": {},
   "source": [
    "#### Slide 10 — Rolling IV Return Correlations (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72476689",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = load_cores_with_auto_fetch(list(tickers), start, end, db_path)\n",
    "panel = build_iv_panel(cores, tolerance=tolerance) if cores else None\n",
    "\n",
    "if panel is None or panel.empty:\n",
    "    print('[WARN] Panel empty — skipping rolling correlations')\n",
    "else:\n",
    "    tgt_col = f'IVRET_{target_ticker}'\n",
    "    if tgt_col not in panel.columns:\n",
    "        print(f'[WARN] Missing target return column: {tgt_col}')\n",
    "    else:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        for peer in tickers:\n",
    "            if peer == target_ticker:\n",
    "                continue\n",
    "            peer_col = f'IVRET_{peer}'\n",
    "            if peer_col not in panel.columns:\n",
    "                continue\n",
    "            s = panel[tgt_col].rolling(roll_window, min_periods=max(5, roll_window//4)).corr(panel[peer_col]).dropna()\n",
    "            if len(s) > 0:\n",
    "                s.rename(peer, inplace=True)\n",
    "                s.plot(label=peer, alpha=0.9)\n",
    "        plt.axhline(0, color='k', lw=0.8)\n",
    "        plt.title(f'Rolling window {roll_window} bars — IV Return Corr vs {target_ticker}')\n",
    "        plt.legend(title='Peer')\n",
    "        plt.tight_layout()\n",
    "        out = plots_dir / f'slide10_rolling_corr_{target_ticker}.png'\n",
    "        plt.savefig(out, dpi=150)\n",
    "        plt.show()\n",
    "        print(f'[SAVED] {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98ed8f",
   "metadata": {},
   "source": [
    "#### Slides 12–13 — Pooled Dataset + Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fe3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ts = pd.Timestamp(start, tz='UTC')\n",
    "end_ts = pd.Timestamp(end, tz='UTC')\n",
    "pooled = build_pooled_iv_return_dataset_time_safe(\n",
    "    tickers=tickers, start=start_ts, end=end_ts, forward_steps=forward_steps, tolerance=tolerance, db_path=db_path\n",
    ")\n",
    "print(f'Pooled rows: {len(pooled):,}, columns: {pooled.shape[1]}')\n",
    "pooled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c45670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_importance(df: pd.DataFrame, target: str):\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError('Empty dataset')\n",
    "    if target not in df.columns:\n",
    "        raise KeyError(f'Missing target: {target}')\n",
    "    y = pd.to_numeric(df[target], errors='coerce')\n",
    "    X = df.drop(columns=[target]).copy()\n",
    "    leak_cols = []\n",
    "    if target == 'iv_clip':\n",
    "        leak_cols += [c for c in ['iv_ret_fwd','iv_ret_fwd_abs','core_iv_ret_fwd_abs'] if c in X.columns]\n",
    "    elif target == 'iv_ret_fwd':\n",
    "        leak_cols += [c for c in ['iv_ret_fwd_abs','core_iv_ret_fwd_abs'] if c in X.columns]\n",
    "    X.drop(columns=leak_cols, inplace=True, errors='ignore')\n",
    "    X = X.select_dtypes(include=['number','bool']).astype(float)\n",
    "    n = len(X); split = int(n*0.8)\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=350, learning_rate=0.05, max_depth=6, subsample=0.9, colsample_bytree=0.9, random_state=42, n_jobs=-1)\n",
    "    model.fit(X.iloc[:split], y.iloc[:split])\n",
    "    pred = model.predict(X.iloc[split:])\n",
    "    rmse = float(np.sqrt(((y.iloc[split:] - pred)**2).mean()))\n",
    "    gain = model.get_booster().get_score(importance_type='gain')\n",
    "    importances = pd.DataFrame([{'feature':k,'gain':v} for k,v in gain.items()]).sort_values('gain', ascending=False)\n",
    "    def feature_ticker(feat: str):\n",
    "        return next((t for t in tickers if t in feat), None)\n",
    "    importances['ticker'] = importances['feature'].apply(feature_ticker)\n",
    "    agg = importances.groupby('ticker', dropna=True)['gain'].sum().sort_values(ascending=False).reset_index().rename(columns={'gain':'agg_gain'})\n",
    "    return model, rmse, importances, agg\n",
    "\n",
    "# Levels\n",
    "model_lvl, rmse_lvl, imp_lvl, agg_lvl = train_and_importance(pooled.copy(), 'iv_clip')\n",
    "print(f'Levels RMSE: {rmse_lvl:.6f}')\n",
    "display(agg_lvl.head(10))\n",
    "plt.figure(figsize=(6,4))\n",
    "colors = agg_lvl['ticker'].apply(lambda t: '#d62728' if t in ['IONQ','RGTI'] else ('#7f7f7f' if t in ['QBTS','QUBT'] else '#1f77b4'))\n",
    "sns.barplot(data=agg_lvl, x='ticker', y='agg_gain', palette=list(colors))\n",
    "plt.title('Slide 12: Pooled IV Level — Per-Ticker Importance (gain)')\n",
    "plt.ylabel('Aggregate gain')\n",
    "plt.tight_layout(); plt.savefig(plots_dir/'slide12_importance_levels.png', dpi=150); plt.show()\n",
    "\n",
    "# Returns\n",
    "model_ret, rmse_ret, imp_ret, agg_ret = train_and_importance(pooled.copy(), 'iv_ret_fwd')\n",
    "print(f'Returns RMSE: {rmse_ret:.6f}')\n",
    "display(agg_ret.head(10))\n",
    "plt.figure(figsize=(6,4))\n",
    "colors = agg_ret['ticker'].apply(lambda t: '#d62728' if t in ['IONQ','RGTI'] else ('#7f7f7f' if t in ['QBTS','QUBT'] else '#1f77b4'))\n",
    "sns.barplot(data=agg_ret, x='ticker', y='agg_gain', palette=list(colors))\n",
    "plt.title('Slide 13: Pooled IV Return — Per-Ticker Importance (gain)')\n",
    "plt.ylabel('Aggregate gain')\n",
    "plt.tight_layout(); plt.savefig(plots_dir/'slide13_importance_returns.png', dpi=150); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
